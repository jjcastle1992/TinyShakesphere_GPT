{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.881084600Z",
     "start_time": "2023-10-30T00:38:48.849931800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "import functorch.dim\n",
    "import torch\n",
    "\n",
    "# toy example\n",
    "# this is to go from tokens not talking to each other to coupling tokens\n",
    "# so that current token (say 5) talks to all past tokens (1, 2, 3, 4)\n",
    "# info flows from previous context to current time. Cant get any info\n",
    "# from future because about to try and predict future.\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2  # batch, time, channels (num parallel contexts being processed, max context length, vocab size)\n",
    "# means in this case we have up to 8 tokens in a batch\n",
    "x = torch.randn(B, T, C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# going to use an average for now that's extremely lossy. \n",
    "# Use average of all preceding elements (get channels for 1, 2, 3, 4, and 5)\n",
    "# if 5th token. Average up all channels. Gives us a feature vector that summerizes\n",
    "# the 5th token in the context of its history. Does lose a ton of info about spatial arrangement of tokens, but using for now.\n",
    "\n",
    "# We want x[b, t] = mean_{i <= t}  x[b, i].\n",
    "# bow is bag of words (word stored on every one of the 8 locations)\n",
    "# NEST FOR LOOPS VERY INEFFICIENT. WILL REWRITE w/ Matrix Mult\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t + 1]  # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.882085800Z",
     "start_time": "2023-10-30T00:38:48.854591600Z"
    }
   },
   "id": "11557dd0d1a78afa"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n"
     ]
    }
   ],
   "source": [
    "print(x[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.882085800Z",
     "start_time": "2023-10-30T00:38:48.859126Z"
    }
   },
   "id": "81cc9a10697d81e2"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1808, -0.0700],\n        [-0.0894, -0.4926],\n        [ 0.1490, -0.3199],\n        [ 0.3504, -0.2238],\n        [ 0.3525,  0.0545],\n        [ 0.0688, -0.0396],\n        [ 0.0927, -0.0682],\n        [-0.0341,  0.1332]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0] # basically at each iteration of xbow, first x is ident to xbow row 0 because only an avg of itself\n",
    "# but with each iteration of xbow, it is an average of all the rows up to that point.\n",
    "# at the end xbow is an average of every row in the x table."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.882085800Z",
     "start_time": "2023-10-30T00:38:48.864377200Z"
    }
   },
   "id": "c9c64ecaff912e"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "---\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=\n",
      "tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b   # @ = matrix mult (so this is a dot b and a is a (3, 3)\n",
    "# b is a (3, 2), and so c (the dot product) is a 3, 2) b/c (3,3) * (3, 2) take the outside terms and throw away inside to get final dims of cross prod\n",
    "print('a=')\n",
    "print(a)\n",
    "print('---')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('---')\n",
    "print('c=')\n",
    "print(c)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.882085800Z",
     "start_time": "2023-10-30T00:38:48.871383700Z"
    }
   },
   "id": "7732e49005ba3ae1"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "---\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=\n",
      "tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# do this again, but using a lower triangular matrix\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b   # @ = matrix mult (so this is a dot b and a is a (3, 3)\n",
    "# b is a (3, 2), and so c (the dot product) is a 3, 2) b/c (3,3) * (3, 2) take the outside terms and throw away inside to get final dims of cross prod\n",
    "print('a=')\n",
    "print(a)\n",
    "print('---')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('---')\n",
    "print('c=')\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.913286400Z",
     "start_time": "2023-10-30T00:38:48.878081600Z"
    }
   },
   "id": "92d9060f722aedd"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "---\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# do this again, but normalize rows so that all rows of 1 add to 1.\n",
    "# so now all rows of a will sum to 1. \n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b   # @ = matrix mult (so this is a dot b and a is a (3, 3)\n",
    "# b is a (3, 2), and so c (the dot product) is a 3, 2) b/c (3,3) * (3, 2) take the outside terms and throw away inside to get final dims of cross prod\n",
    "print('a=')\n",
    "print(a)\n",
    "print('---')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('---')\n",
    "print('c=')\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.913286400Z",
     "start_time": "2023-10-30T00:38:48.884653100Z"
    }
   },
   "id": "6d34c5e5e1224d7a"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new version of average matrix called wei (short for weightts)\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "wei"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.914247500Z",
     "start_time": "2023-10-30T00:38:48.894440500Z"
    }
   },
   "id": "846c3e3aebffe9c2"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use weighted aggreg using matrix multiply. Weights specified in T x T array\n",
    "# a is now average matrix called wei (short for weights)\n",
    "# b is x\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x  # a dot b where a is (T, T) @ b (B, T, C) so ----> (B, T, T) @ (B, T, C) applies batching\n",
    "# so for each batch element there will be a (T, T) @  (T, C) ---> (B, T, C) again. \n",
    "torch.allclose(xbow, xbow2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.914247500Z",
     "start_time": "2023-10-30T00:38:48.897700400Z"
    }
   },
   "id": "71d4426d7d66a30b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "print(xbow[0])\n",
    "print(xbow2[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.914765400Z",
     "start_time": "2023-10-30T00:38:48.904602500Z"
    }
   },
   "id": "bc55e15b0a50ef55"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# Final version of this: Softmax (also normalizes so each row = 1)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:38:48.926764700Z",
     "start_time": "2023-10-30T00:38:48.911284500Z"
    }
   },
   "id": "4d3e51925a95a6eb"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 8, 16])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: Self-Attention (Self-Atten b/c key, queries, and vals all come from x\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32  # batch, time, channels (# ind. parallel seqs, block size (context), vocab size)\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# single head performing self-attention\n",
    "head_size = 16  # hyperparam\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))  # decoder block that prevents future nodes from talking to current or past nodes.\n",
    "# delete above if you want all nodes to talk to each other in the batch. (i.e. all 8 nodes in the context block to talk even if you're at position 0\n",
    "# in the batch. \n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)  # this is the thing that gets aggregated between the different nodes (x is like private info to the node itself (say node 5). \n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:44:37.421972700Z",
     "start_time": "2023-10-30T00:44:37.411250900Z"
    }
   },
   "id": "171314df7f9a7981"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]  # data dependent wei where the token influences the weight (not uniform as before)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:40:46.229558100Z",
     "start_time": "2023-10-30T00:40:46.223374100Z"
    }
   },
   "id": "fbcc79df0473896d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
